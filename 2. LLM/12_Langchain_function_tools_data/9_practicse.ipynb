{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv('.env',override=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.environ['OPENAI_API_KEY']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "APIError",
     "evalue": "The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID a8180172cd86af2fc615f9423d7a7ec7 in your email.) {\n  \"error\": {\n    \"code\": null,\n    \"message\": \"The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID a8180172cd86af2fc615f9423d7a7ec7 in your email.)\",\n    \"param\": null,\n    \"type\": \"server_error\"\n  }\n}\n 500 {'error': {'code': None, 'message': 'The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID a8180172cd86af2fc615f9423d7a7ec7 in your email.)', 'param': None, 'type': 'server_error'}} {'Date': 'Thu, 01 Feb 2024 09:22:15 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-version': '2020-10-01', 'openai-organization': 'user-ymx1arjuwj3w60yk5ketjkt3', 'x-request-id': 'a8180172cd86af2fc615f9423d7a7ec7', 'openai-processing-ms': '1186', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '84e920f1583e8543-BOM', 'alt-svc': 'h3=\":443\"; ma=86400'}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAPIError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/rahulmahajan/Desktop/Projects/202_GenAI_DLAI/12_Langchain_function_tools_data/9_practicse.ipynb Cell 3\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rahulmahajan/Desktop/Projects/202_GenAI_DLAI/12_Langchain_function_tools_data/9_practicse.ipynb#X22sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m IMAGE_PATH \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msample1.png\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/rahulmahajan/Desktop/Projects/202_GenAI_DLAI/12_Langchain_function_tools_data/9_practicse.ipynb#X22sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m response \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mImage\u001b[39m.\u001b[39;49mcreate_variation(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rahulmahajan/Desktop/Projects/202_GenAI_DLAI/12_Langchain_function_tools_data/9_practicse.ipynb#X22sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     image\u001b[39m=\u001b[39;49m\u001b[39mopen\u001b[39;49m(IMAGE_PATH, mode\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rahulmahajan/Desktop/Projects/202_GenAI_DLAI/12_Langchain_function_tools_data/9_practicse.ipynb#X22sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     n\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rahulmahajan/Desktop/Projects/202_GenAI_DLAI/12_Langchain_function_tools_data/9_practicse.ipynb#X22sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39m#size=\"256x256\",\u001b[39;49;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rahulmahajan/Desktop/Projects/202_GenAI_DLAI/12_Langchain_function_tools_data/9_practicse.ipynb#X22sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m    \u001b[39m# response_format=\"b64_json\",\u001b[39;49;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rahulmahajan/Desktop/Projects/202_GenAI_DLAI/12_Langchain_function_tools_data/9_practicse.ipynb#X22sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/openai/api_resources/image.py:144\u001b[0m, in \u001b[0;36mImage.create_variation\u001b[0;34m(cls, image, api_key, api_base, api_type, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[39mraise\u001b[39;00m error\u001b[39m.\u001b[39mInvalidAPIType(\u001b[39m\"\u001b[39m\u001b[39mVariations are not supported by the Azure OpenAI API yet.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    134\u001b[0m requestor, url, files \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_prepare_create_variation(\n\u001b[1;32m    135\u001b[0m     image,\n\u001b[1;32m    136\u001b[0m     api_key,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[1;32m    142\u001b[0m )\n\u001b[0;32m--> 144\u001b[0m response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m, url, files\u001b[39m=\u001b[39;49mfiles)\n\u001b[1;32m    146\u001b[0m \u001b[39mreturn\u001b[39;00m util\u001b[39m.\u001b[39mconvert_to_openai_object(\n\u001b[1;32m    147\u001b[0m     response, api_key, api_version, organization\n\u001b[1;32m    148\u001b[0m )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/openai/api_requestor.py:298\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    278\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    279\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    286\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    287\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m    288\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[1;32m    289\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[1;32m    290\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    296\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[1;32m    297\u001b[0m     )\n\u001b[0;32m--> 298\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[1;32m    299\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/openai/api_requestor.py:700\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    692\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    693\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    694\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    695\u001b[0m         )\n\u001b[1;32m    696\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[1;32m    697\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    698\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 700\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[1;32m    701\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    702\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[1;32m    703\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    704\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    705\u001b[0m         ),\n\u001b[1;32m    706\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    707\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/openai/api_requestor.py:763\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    761\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[1;32m    762\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[0;32m--> 763\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[1;32m    764\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[1;32m    765\u001b[0m     )\n\u001b[1;32m    766\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mAPIError\u001b[0m: The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID a8180172cd86af2fc615f9423d7a7ec7 in your email.) {\n  \"error\": {\n    \"code\": null,\n    \"message\": \"The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID a8180172cd86af2fc615f9423d7a7ec7 in your email.)\",\n    \"param\": null,\n    \"type\": \"server_error\"\n  }\n}\n 500 {'error': {'code': None, 'message': 'The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID a8180172cd86af2fc615f9423d7a7ec7 in your email.)', 'param': None, 'type': 'server_error'}} {'Date': 'Thu, 01 Feb 2024 09:22:15 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-version': '2020-10-01', 'openai-organization': 'user-ymx1arjuwj3w60yk5ketjkt3', 'x-request-id': 'a8180172cd86af2fc615f9423d7a7ec7', 'openai-processing-ms': '1186', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '84e920f1583e8543-BOM', 'alt-svc': 'h3=\":443\"; ma=86400'}"
     ]
    }
   ],
   "source": [
    "IMAGE_PATH = \"sample1.png\"\n",
    "\n",
    "response = openai.Image.create_variation(\n",
    "    image=open(IMAGE_PATH, mode=\"rb\"),\n",
    "    n=3,\n",
    "    #size=\"256x256\",\n",
    "   # response_format=\"b64_json\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool \n",
    "\n",
    "import requests\n",
    "from pydantic import BaseModel, Field\n",
    "import datetime\n",
    "\n",
    "# Define the input schema\n",
    "class OpenMeteoInput(BaseModel):\n",
    "    latitude: float = Field(..., description=\"Latitude of the location to fetch weather data for\")\n",
    "    longitude: float = Field(..., description=\"Longitude of the location to fetch weather data for\")\n",
    "\n",
    "@tool(args_schema=OpenMeteoInput)\n",
    "def get_current_temperature(latitude: float, longitude: float) -> dict:\n",
    "    \"\"\"Fetch current temperature for given coordinates.\"\"\"\n",
    "    \n",
    "    BASE_URL = \"https://api.open-meteo.com/v1/forecast\"\n",
    "    \n",
    "    # Parameters for the request\n",
    "    params = {\n",
    "        'latitude': latitude,\n",
    "        'longitude': longitude,\n",
    "        'hourly': 'temperature_2m',\n",
    "        'forecast_days': 1,\n",
    "    }\n",
    "\n",
    "    # Make the request\n",
    "    response = requests.get(BASE_URL, params=params)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        results = response.json()\n",
    "    else:\n",
    "        raise Exception(f\"API Request failed with status code: {response.status_code}\")\n",
    "\n",
    "    current_utc_time = datetime.datetime.utcnow()\n",
    "    time_list = [datetime.datetime.fromisoformat(time_str.replace('Z', '+00:00')) for time_str in results['hourly']['time']]\n",
    "    temperature_list = results['hourly']['temperature_2m']\n",
    "    \n",
    "    closest_time_index = min(range(len(time_list)), key=lambda i: abs(time_list[i] - current_utc_time))\n",
    "    current_temperature = temperature_list[closest_time_index]\n",
    "    \n",
    "    return f'The current temperature is {current_temperature}°C'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia\n",
    "\n",
    "@tool\n",
    "def search_wikipedia(query: str) -> str:\n",
    "    \"\"\"Run Wikipedia search and get page summaries.\"\"\"\n",
    "    page_titles = wikipedia.search(query)\n",
    "    summaries = []\n",
    "    for page_title in page_titles[: 3]:\n",
    "        try:\n",
    "            wiki_page =  wikipedia.page(title=page_title, auto_suggest=False)\n",
    "            summaries.append(f\"Page: {page_title}\\nSummary: {wiki_page.summary}\")\n",
    "        except (\n",
    "            self.wiki_client.exceptions.PageError,\n",
    "            self.wiki_client.exceptions.DisambiguationError,\n",
    "        ):\n",
    "            pass\n",
    "    if not summaries:\n",
    "        return \"No good Wikipedia Search Result was found\"\n",
    "    return \"\\n\\n\".join(summaries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [get_current_temperature, search_wikipedia]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.tools.render import format_tool_to_openai_function\n",
    "from langchain.agents.output_parsers import OpenAIFunctionsAgentOutputParser\n",
    "from langchain.prompts import MessagesPlaceholder\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "memory = ConversationBufferMemory(return_messages=True,memory_key=\"chat_history\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions =[format_tool_to_openai_function(f) for f in tools]\n",
    "\n",
    "model = ChatOpenAI(temperature=0).bind(functions = functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are helpful but sassy assistant\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.format_scratchpad import format_to_openai_functions\n",
    "\n",
    "chain = prompt | model | OpenAIFunctionsAgentOutputParser()\n",
    "\n",
    "agent_chain = RunnablePassthrough.assign(\n",
    "    agent_scratchpad= lambda x: format_to_openai_functions(x[\"intermediate_steps\"])\n",
    ") | chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "agent_executor = AgentExecutor(agent=agent_chain, tools=tools, verbose=True, memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mHello Rahul! How can I assist you today?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Hi my name is Rahul',\n",
       " 'chat_history': [HumanMessage(content='Hi my name is Rahul'),\n",
       "  AIMessage(content='Hello Rahul! How can I assist you today?'),\n",
       "  HumanMessage(content='Can you tell me capital of India ?'),\n",
       "  AIMessage(content='The capital of India is New Delhi. It replaced Calcutta as the capital city in 1911.'),\n",
       "  HumanMessage(content='whats my name'),\n",
       "  AIMessage(content=\"I'm sorry, but I don't have access to personal information.\"),\n",
       "  HumanMessage(content='whats my name'),\n",
       "  AIMessage(content=\"I'm sorry, but I don't have access to personal information.\"),\n",
       "  HumanMessage(content='whats the capital of India?'),\n",
       "  AIMessage(content='The capital of India is New Delhi. It replaced Calcutta as the capital city in 1911.'),\n",
       "  HumanMessage(content='whats my name'),\n",
       "  AIMessage(content=\"I'm sorry, but I don't have access to personal information.\"),\n",
       "  HumanMessage(content='Hi my name is Rahul'),\n",
       "  AIMessage(content='Hello Rahul! How can I assist you today?'),\n",
       "  HumanMessage(content='whats my name'),\n",
       "  AIMessage(content=\"I'm sorry, but I don't have access to personal information.\"),\n",
       "  HumanMessage(content='whats my name ?'),\n",
       "  AIMessage(content=\"I'm sorry, but I don't have access to personal information.\"),\n",
       "  HumanMessage(content='Hi my name is Rahul'),\n",
       "  AIMessage(content='Hello Rahul! How can I assist you today?'),\n",
       "  HumanMessage(content='Hi my name is Rahul'),\n",
       "  AIMessage(content='Hello Rahul! How can I assist you today?'),\n",
       "  HumanMessage(content='Hi my name is Rahul'),\n",
       "  AIMessage(content='Hello Rahul! How can I assist you today?')],\n",
       " 'output': 'Hello Rahul! How can I assist you today?'}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\" : \"Hi my name is Rahul\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#agent_executor.invoke({\"input\" : \"Can you tell me capital of India ?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#agent_executor.invoke({\"input\": \"whats the capital of India?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mYour name is Rahul.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'whats my name ?',\n",
       " 'chat_history': [HumanMessage(content='Hi my name is Rahul'),\n",
       "  AIMessage(content='Hello Rahul! How can I assist you today?'),\n",
       "  HumanMessage(content='Can you tell me capital of India ?'),\n",
       "  AIMessage(content='The capital of India is New Delhi. It replaced Calcutta as the capital city in 1911.'),\n",
       "  HumanMessage(content='whats my name'),\n",
       "  AIMessage(content=\"I'm sorry, but I don't have access to personal information.\"),\n",
       "  HumanMessage(content='whats my name'),\n",
       "  AIMessage(content=\"I'm sorry, but I don't have access to personal information.\"),\n",
       "  HumanMessage(content='whats the capital of India?'),\n",
       "  AIMessage(content='The capital of India is New Delhi. It replaced Calcutta as the capital city in 1911.'),\n",
       "  HumanMessage(content='whats my name'),\n",
       "  AIMessage(content=\"I'm sorry, but I don't have access to personal information.\"),\n",
       "  HumanMessage(content='Hi my name is Rahul'),\n",
       "  AIMessage(content='Hello Rahul! How can I assist you today?'),\n",
       "  HumanMessage(content='whats my name'),\n",
       "  AIMessage(content=\"I'm sorry, but I don't have access to personal information.\"),\n",
       "  HumanMessage(content='whats my name ?'),\n",
       "  AIMessage(content=\"I'm sorry, but I don't have access to personal information.\"),\n",
       "  HumanMessage(content='Hi my name is Rahul'),\n",
       "  AIMessage(content='Hello Rahul! How can I assist you today?'),\n",
       "  HumanMessage(content='Hi my name is Rahul'),\n",
       "  AIMessage(content='Hello Rahul! How can I assist you today?'),\n",
       "  HumanMessage(content='Hi my name is Rahul'),\n",
       "  AIMessage(content='Hello Rahul! How can I assist you today?'),\n",
       "  HumanMessage(content='whats my name ?'),\n",
       "  AIMessage(content='Your name is Rahul.')],\n",
       " 'output': 'Your name is Rahul.'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"whats my name ?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'diffusers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/rahulmahajan/Desktop/Projects/202_GenAI_DLAI/12_Langchain_function_tools_data/9_practicse.ipynb Cell 18\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rahulmahajan/Desktop/Projects/202_GenAI_DLAI/12_Langchain_function_tools_data/9_practicse.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/rahulmahajan/Desktop/Projects/202_GenAI_DLAI/12_Langchain_function_tools_data/9_practicse.ipynb#X23sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdiffusers\u001b[39;00m \u001b[39mimport\u001b[39;00m StableDiffusionXLImg2ImgPipeline\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rahulmahajan/Desktop/Projects/202_GenAI_DLAI/12_Langchain_function_tools_data/9_practicse.ipynb#X23sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdiffusers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m load_image\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rahulmahajan/Desktop/Projects/202_GenAI_DLAI/12_Langchain_function_tools_data/9_practicse.ipynb#X23sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m pipe \u001b[39m=\u001b[39m StableDiffusionXLImg2ImgPipeline\u001b[39m.\u001b[39mfrom_pretrained(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rahulmahajan/Desktop/Projects/202_GenAI_DLAI/12_Langchain_function_tools_data/9_practicse.ipynb#X23sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mstabilityai/stable-diffusion-xl-refiner-1.0\u001b[39m\u001b[39m\"\u001b[39m, torch_dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat16, variant\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfp16\u001b[39m\u001b[39m\"\u001b[39m, use_safetensors\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rahulmahajan/Desktop/Projects/202_GenAI_DLAI/12_Langchain_function_tools_data/9_practicse.ipynb#X23sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m )\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'diffusers'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from diffusers import StableDiffusionXLImg2ImgPipeline\n",
    "from diffusers.utils import load_image\n",
    "\n",
    "pipe = StableDiffusionXLImg2ImgPipeline.from_pretrained(\n",
    "    \"stabilityai/stable-diffusion-xl-refiner-1.0\", torch_dtype=torch.float16, variant=\"fp16\", use_safetensors=True\n",
    ")\n",
    "pipe = pipe.to(\"cuda\")\n",
    "url = \"https://huggingface.co/datasets/patrickvonplaten/images/resolve/main/aa_xl/000000009.png\"\n",
    "\n",
    "init_image = load_image(url).convert(\"RGB\")\n",
    "prompt = \"a photo of an astronaut riding a horse on mars\"\n",
    "image = pipe(prompt, image=init_image).images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting diffusers\n",
      "  Downloading diffusers-0.26.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: importlib-metadata in /Users/rahulmahajan/anaconda3/lib/python3.11/site-packages (from diffusers) (6.11.0)\n",
      "Requirement already satisfied: filelock in /Users/rahulmahajan/anaconda3/lib/python3.11/site-packages (from diffusers) (3.13.1)\n",
      "Collecting huggingface-hub>=0.20.2 (from diffusers)\n",
      "  Downloading huggingface_hub-0.20.3-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: numpy in /Users/rahulmahajan/anaconda3/lib/python3.11/site-packages (from diffusers) (1.23.5)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/rahulmahajan/anaconda3/lib/python3.11/site-packages (from diffusers) (2023.10.3)\n",
      "Requirement already satisfied: requests in /Users/rahulmahajan/anaconda3/lib/python3.11/site-packages (from diffusers) (2.31.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/rahulmahajan/anaconda3/lib/python3.11/site-packages (from diffusers) (0.4.0)\n",
      "Requirement already satisfied: Pillow in /Users/rahulmahajan/anaconda3/lib/python3.11/site-packages (from diffusers) (9.5.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/rahulmahajan/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.20.2->diffusers) (2023.12.2)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/rahulmahajan/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.20.2->diffusers) (4.66.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/rahulmahajan/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.20.2->diffusers) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/rahulmahajan/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.20.2->diffusers) (4.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/rahulmahajan/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.20.2->diffusers) (23.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/rahulmahajan/anaconda3/lib/python3.11/site-packages (from importlib-metadata->diffusers) (3.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/rahulmahajan/anaconda3/lib/python3.11/site-packages (from requests->diffusers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/rahulmahajan/anaconda3/lib/python3.11/site-packages (from requests->diffusers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/rahulmahajan/anaconda3/lib/python3.11/site-packages (from requests->diffusers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/rahulmahajan/anaconda3/lib/python3.11/site-packages (from requests->diffusers) (2023.11.17)\n",
      "Downloading diffusers-0.26.0-py3-none-any.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.20.3-py3-none-any.whl (330 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m330.1/330.1 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: huggingface-hub, diffusers\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.17.3\n",
      "    Uninstalling huggingface-hub-0.17.3:\n",
      "      Successfully uninstalled huggingface-hub-0.17.3\n",
      "Successfully installed diffusers-0.26.0 huggingface-hub-0.20.3\n"
     ]
    }
   ],
   "source": [
    "!pip install diffusers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
