{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ou could experiment with a more \n",
    "complicated embedding adapter model using a full-blown \n",
    "neural network or even a transformer layer. \n",
    "Similarly, you can use a more complex \n",
    "relevance modeling model rather than just using the cross-encoder \n",
    "as we described in the lab. And finally, an often overlooked piece \n",
    "is that the quality of retrieved results often depends \n",
    "on the way that your data is chunked before it's stored \n",
    "in the retrieval system itself. \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](image-11.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
