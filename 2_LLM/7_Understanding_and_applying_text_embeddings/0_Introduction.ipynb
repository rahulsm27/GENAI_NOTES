{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text embeddings. -> Sentence level embeddings\n",
    "\"\"\"\n",
    "how to compute embeddings, that is feature vector representations of text sequences of arbitrary length, and we'll see how these sentence embeddings are a powerful tool for many applications like classification, outlier detection, and text clustering. \n",
    "\n",
    "If you've heard of word embedding algorithms like Word2Vec or GloVe, \n",
    "that just examine a single word at a time, this is a bit like that, but much more powerful, and much more general because it operates at \n",
    "the level of the meaning of a sentence or even a paragraph of text, and also works for sentences that contain words not seen in the training set. \n",
    "\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
